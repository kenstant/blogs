---
title: 积分消费日志表数据迁移
date: 2025-12-24
---

# 积分消费日志表数据迁移

## 需求背景
1. 原先积分消费日志表存放在PolarDB中，单表数据已经达到4亿多条，故决定将数据迁移到lindorm中去。
2. 同时还有一个积分明细的查询需求，所以在同步数据的时候顺便进行数据的清洗整理方便后面业务需求开发。
3. 数据清洗主要是业务层面的字段添加和修改，根据原有数据进行一些字段的补充和调整，以满足后续业务查询需求。



## 表分析

1. 原表是一张积分消费日志的记录表，只会有新增，没有更新和删除操作。
2. 最开始是从MySQL迁移到PolarDB for MySQL版，所以主键一直是自增id。
3. Lindorm是一个分布式的数据库，没有自增id，需要自己设计和生成主键id。

### 主键设计

1. **唯一ID生成**：使用雪花算法生成唯一ID，作为业务层面的唯一标识。
2. **主键设计**：Lindorm的主键是根据几个业务列组合而成，这样设计更符合Lindorm的数据查找特性，能够提高查询效率。



## 技术方案

### 方案一：（未采用）
1. 将`源表`数据全量同步到阿里云`MaxCompute`中（大数据离线计算系统），然后按照业务需求清洗数据，最后写入`目标表`中去。
2. 后续利用 mq和定时任务进行历史数据的同步和双写。因为最终没有采用，且做法和`方案二`方法差不多，故此处不详细描述。



拒绝原因：

1. 时间上可能更快，但是最后双写同步阶段清洗数据的代码需要再大数据系统和Java应用层都写一遍，有点重复工作，并且工作量也不小。
2. MaxCompute原有资源在其他的项目中占用了，不太能腾出来给我们使用。

### 方案二：（采用）

1. **创建同步错误记录表**：创建一张同步错误记录表，专门记录同步出错的`源表id及错误信息`，方便后续处理。

2. **历史数据全量同步**：记录下此时此刻`源表`中的最大id值，记为`a`，先将`0 < id < a`的数据同步到`目标表`。
   - 利用单机定时任务按照id分段扫描源表，先检查目标表中是否存在，然后再同步。
   - 失败的写进失败记录表，同步成功的incr一下`redis中的同步成功条数`。
   - 每个分段处理完之后，更新一下redis中的同步进度，以便应用重启时的断点续写处理。
   - **分段策略演进**：
     - 最初采用每段100条，5个线程并发处理，但经过估算发现全部写完需要花费一个月时间。
     - 优化后改为每段200条，10个线程并发处理，大大提升了同步效率。

3. **全量同步完成检查**：全部写完后记录下`目标表`中的最大值id，记为`x`（x<=a），检查两表条数是否一样。

4. **开启双写同步**：利用`RocketMQ`进行双写同步，记录下双写开始的id最小值，记为`y`。观察双写阶段的数据条数是否一致，无问题则进行下一步。

5. **双写期间历史数据同步**：利用`定时任务`，将`x < id < y`的历史数据逐条同步到目标表（同步骤2）。这一步是在双写开启后进行的，确保双写期间产生的数据也能被同步。

6. **数据一致性检查**：第5步完成后，检查两表总条数，如果差距不大则进行下一步，如果差距过大，需要检查`id > x`的数据中是哪里出了问题。

7. **切换写入目标**：原来写入`源表`的地方直接改成写入`目标表`，但是双写时用到的`MQ投递和消费不停`，应用全部重启之后，应该就不会再产生新的消息。切完之后，没有问题则去掉MQ的投递和消费。

8. **处理错误数据**：处理错误表中的数据。

## 最终效果

### 迁移结果
- **总迁移数据量**：4.5亿条
- **错误数据量**：1500多条
- **错误率**：约0.0003%，错误率极低

### 问题处理

迁移过程中遇到的主要错误类型是 `expected 1, but found 2` 这种错误，即期望查询到1条数据，但实际查询到了2条数据。这种情况通常是由于数据重复或者查询条件不够精确导致的。

**解决方案**：对于这类错误，采用 `limit 1` 的方式进行处理，只取第一条数据，确保数据同步的顺利进行。

### 经验总结

1. **分段策略优化**：通过调整分段大小和并发线程数，可以显著提升迁移效率。从最初的每段100条、5线程，优化到每段200条、10线程，大大缩短了迁移时间。

2. **先双写再同步历史数据**：采用先开启双写，再同步双写期间历史数据的策略，可以确保数据不丢失，同时保证迁移过程的平滑进行。

3. **错误处理机制**：建立完善的错误记录表，对于迁移过程中的错误数据进行记录和处理，确保最终数据的完整性。

4. **主键设计**：根据Lindorm的特性，采用多列组合主键的方式，能够更好地利用Lindorm的查询优势，提升后续查询性能。



